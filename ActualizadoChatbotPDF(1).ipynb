{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d77LURgOEfBJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain"
      ],
      "metadata": {
        "id": "TE_Z1B6LIcgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain-community"
      ],
      "metadata": {
        "id": "xJRMglw6JASz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "NPCbUuE6I1PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = input(\"Enter PDF file path: \")\n",
        "loader = PyPDFLoader(path)\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "MTyG2Nj_N3NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "docs = splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "vsTXIEYUU8c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs)"
      ],
      "metadata": {
        "id": "-jfA7SzOVWR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q chromadb"
      ],
      "metadata": {
        "id": "WUCqjG5dIncc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "YguR487cJQBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade huggingface_hub"
      ],
      "metadata": {
        "id": "fOkJ5KyfJeUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HUGGINGFACEHUB_API_TOKEN = \"\""
      ],
      "metadata": {
        "id": "h50GJl3NJgTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\""
      ],
      "metadata": {
        "id": "Ahg6faWGJj67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "\n",
        "\n",
        "huggingface_embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=docs, embedding=huggingface_embeddings)"
      ],
      "metadata": {
        "id": "ywCCEMRvJmpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m406OeoIHsJq",
        "outputId": "a3a5cbe3-3d40-4732-a0af-a491a0d12a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = \"\"\n",
        "    # getpass.getpass(\"Enter your Groq API key:\")"
      ],
      "metadata": {
        "id": "8bhE-bZrH6Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    temperature=0.6,\n",
        "    max_tokens=1024,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "2ygYH7y8IP8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "LilLVKj4LqHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "bQdm6uNVMKZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ],
      "metadata": {
        "id": "698APxfJJmcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"que es el pago adicional segun la UCI\"\n",
        "llm_response = qa_chain(query)\n"
      ],
      "metadata": {
        "id": "PjAVxVtEYh9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " text = llm_response['result']\n"
      ],
      "metadata": {
        "id": "HvUx6Uo5f5S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    texto_sin_caracteres = re.sub(r'[^\\w\\s]', '', texto)\n",
        "\n",
        "    parrafos = texto_sin_caracteres.split('\\n')\n",
        "\n",
        "    parrafos = [p for p in parrafos if p.strip()]\n",
        "\n",
        "    texto_limpio = '\\n'.join(parrafos)\n",
        "\n",
        "    return texto_limpio\n",
        "\n",
        "\n",
        "texto_limpio = limpiar_texto(text)\n",
        "print(texto_limpio)"
      ],
      "metadata": {
        "id": "WgTfMlg_bGX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}